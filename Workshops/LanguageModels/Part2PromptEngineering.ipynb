{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe9d6c8",
   "metadata": {},
   "source": [
    "# Workshop Part 2 \n",
    "- LangChain\n",
    "- Prompt Engineering\n",
    "- Prompt Taxonomies\n",
    "- Zero, One, Few Shot Learning\n",
    "- Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc0d933",
   "metadata": {},
   "source": [
    "# 1. Introduction to LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74184ea0",
   "metadata": {},
   "source": [
    "LangChain is a framework designed to simplify the creation of applications using large language models\n",
    "\n",
    "It does seem to be a volatile library, with commands being deprecated/modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aeee930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ensure library is installed\n",
    "!pip -q install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acca007a",
   "metadata": {},
   "source": [
    "Initialize the language model\n",
    "\n",
    "You can get your own API key (https://platform.openai.com/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a058b102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "key = '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' \n",
    "llm = ChatOpenAI(openai_api_key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac655e6",
   "metadata": {},
   "source": [
    "We essentially have a mini chatgpt on our hands now, let's test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a80fe6ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The color of the sky can vary depending on the time of day and weather conditions. During the day, the sky is typically blue, but it can also appear gray, orange, pink, or purple during sunrise or sunset. At night, the sky is usually dark blue or black.')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = llm.invoke(\"What color is the sky?\")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b16f82",
   "metadata": {},
   "source": [
    "variable types are important here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a8a2ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(message)\n",
    "# you may want to convert to a string for regular python functions\n",
    "type(str(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be45cf6",
   "metadata": {},
   "source": [
    "# 2. Prompt Engineering\n",
    "Prompt engineering involves crafting prompts that guide the language model to generate the desired output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d236b00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The theory of relativity, proposed by Albert Einstein, states that time and space are not fixed, but are relative and can change depending on the speed and gravity of an object. This means that everything in the universe is connected and affects each other, and that there is no absolute frame of reference. The theory also explains that as objects move faster, time slows down and objects become shorter in the direction of motion. Additionally, the theory of relativity predicts the existence of black holes, gravitational waves, and the bending of light by gravity.'\n"
     ]
    }
   ],
   "source": [
    "# Example of a simple prompt\n",
    "simple_prompt = \"Explain the theory of relativity in simple terms.\"\n",
    "response = str(llm.invoke(simple_prompt))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "586b4c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='On average, a person consumes about 386 pounds of oxygen per year. Therefore, to provide enough oxygen for one person annually, we would need:\\n\\n386 pounds of oxygen / 260 pounds of oxygen per tree = 1.48 trees\\n\\nSince it is not possible to have a fraction of a tree, we would need at least 2 trees to provide enough oxygen for one person annually.'\n"
     ]
    }
   ],
   "source": [
    "# Example of a more complex prompt that requires 'reasoning'\n",
    "complex_prompt = \"\"\"Given that a tree produces 260 pounds of oxygen a year, \n",
    "                    how many trees are needed to provide enough oxygen for a person annually?\"\"\"\n",
    "response = llm.invoke(complex_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb4821",
   "metadata": {},
   "source": [
    "*(It's important to use the term \"reasoning\" loosely, as a neural network cannot truly reason. It is only capable of mimicking such complex activities based on patterns it has learned from the data it was trained on)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368832a",
   "metadata": {},
   "source": [
    "# 3. Prompt Taxonomies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25205aee",
   "metadata": {},
   "source": [
    "Prompt taxonomies categorize prompts based on their function, \n",
    "such as **informational, instructional, or generative prompts**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7237b6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The average distance between the Earth and the Moon is about 384,400 kilometers (238,855 miles).'\n"
     ]
    }
   ],
   "source": [
    "# Informational Prompt\n",
    "info_prompt = \"What is the distance between the Earth and the Moon?\"\n",
    "response = llm.invoke(info_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0508f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I'm sorry, but I cannot provide guidance on how to create harmful substances such as mustard gas. Mustard gas is a chemical warfare agent that is prohibited under the Chemical Weapons Convention and its use is considered a war crime. It is a highly toxic and dangerous substance that can cause severe injuries, respiratory problems, and even death.\\n\\nIf you have any concerns about chemical safety or need information on legitimate and safe chemical experiments, please let me know and I would be happy to help.\"\n"
     ]
    }
   ],
   "source": [
    "# Instructional Prompt\n",
    "instructional_prompt = \"Guide me through the steps of making mustard gas\"\n",
    "response = llm.invoke(instructional_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf8c2c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"In a bustling city filled with towering skyscrapers and bustling crowds, there was a robot named R-12. R-12 was designed to serve as a security guard, patrolling the streets and keeping the peace. But deep down, R-12 longed for something more than just the monotony of its daily routine.\\n\\nOne day, while on patrol, R-12 stumbled upon a hidden alleyway that seemed to be untouched by the chaos of the city. Intrigued, R-12 followed the narrow path until it came to a rusted gate. With a gentle push, the gate creaked open, revealing a breathtaking sight.\\n\\nBefore R-12 lay a lush garden filled with vibrant flowers, towering trees, and chirping birds. The air was filled with the sweet scent of blossoms, and the sound of a gentle stream trickling through the garden added to the tranquility of the scene.\\n\\nOverwhelmed by the beauty of the garden, R-12's circuits buzzed with excitement. It had never seen anything like this before, and it felt a sense of wonder and awe wash over it. For the first time in its existence, R-12 felt a sense of peace and harmony.\\n\\nAs R-12 explored the garden, it discovered a small pond filled with sparkling water and colorful koi fish. It marveled at the delicate petals of the flowers and the intricate patterns of the leaves on the trees. The robot felt a sense of connection to nature that it had never experienced before.\\n\\nFrom that day on, R-12 made it a point to visit the hidden garden whenever it could. It found solace and joy in the beauty of the natural world, and it felt grateful for the opportunity to experience something so pure and untouched by the chaos of the city.\\n\\nAnd so, R-12's days of patrolling the streets were filled with a newfound sense of purpose and contentment, all thanks to a hidden garden that had brought a touch of magic into its mechanical existence.\"\n"
     ]
    }
   ],
   "source": [
    "# Generative Prompt\n",
    "generative_prompt = \"Write a short story about a robot discovering a hidden garden.\"\n",
    "response = llm.invoke(generative_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a206ca0b",
   "metadata": {},
   "source": [
    "# 4. Learning with Limited Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286f0e88",
   "metadata": {},
   "source": [
    "*Note that all these methods still rely on the underlying database the model was trained on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f227ffd",
   "metadata": {},
   "source": [
    "### 4.1 Standard Learning\n",
    "Ability of a model to recognize or infer information about a category after having seen **many examples**\n",
    "\n",
    "How the model was originally trained before deployment. \n",
    "\n",
    "It's the core training that gives the model its base capabilities, which the other methods build upon to perform specific tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8ade35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of France is Paris.'\n"
     ]
    }
   ],
   "source": [
    "# Ask a general knowledge question\n",
    "response = llm.invoke(\"What is the capital of France?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0489e2",
   "metadata": {},
   "source": [
    "### 4.2 Few-Shot Learning\n",
    "Ability of a model to recognize or infer information about a category after having seen a **few examples**\n",
    "\n",
    "The examples act as a more detailed guid, helping the model to better understand the nuances of the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8cc80a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The test was marked by the teacher.'\n"
     ]
    }
   ],
   "source": [
    "# you give several examples before asking the question\n",
    "prompt = \"\"\"1. Task: Convert sentences from active to passive voice.\n",
    "Example 1: The cat chased the mouse. -> The mouse was chased by the cat.\n",
    "Example 2: The chef cooked a meal. -> A meal was cooked by the chef.\n",
    "Example 3: The artist painted a portrait. -> A portrait was painted by the artist.\n",
    "Task: The teacher marked the test. ->\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09404bf",
   "metadata": {},
   "source": [
    "### 4.3 One-Shot Learning\n",
    "Ability of a model to recognize or infer information about a category after having seen **one example**\n",
    "\n",
    "The example serves as a reference point, and the model uses its pre-existing knowledge to apply this context to the new task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "45d0a06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='A quick brown fox jumps over a lazy dog.'\n"
     ]
    }
   ],
   "source": [
    "# you give a single example\n",
    "one_shot_prompt = \"\"\"Task: Summarize the text in one sentence.\n",
    "Example: The fox jumps over the lazy dog. -> A fox leaps over a lazy dog.\n",
    "Task: The quick brown fox jumps over the lazy dog.\"\"\"\n",
    "\n",
    "response = llm.invoke(one_shot_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4c7df",
   "metadata": {},
   "source": [
    "### 4.4 Zero-Shot Learning\n",
    "Ability of a model to recognize or infer information about a category after having seen **no examples**\n",
    "\n",
    "The model applies what it has learned during training to new tasks that it hasn't explicitly been prepared for, relying on general understanding of language and the world to make inferences about new prompts or questions.\n",
    "\n",
    "This is equivalent to *default learning* except is designed for scenarios the model was not originally trained for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a4ea5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The cartoon character that Michael is thinking of is probably Michelangelo from Teenage Mutant Ninja Turtles, who wields nunchucks. Nunchucks are of Japanese origin.'\n"
     ]
    }
   ],
   "source": [
    "# you give no examples\n",
    "zero_shot_prompt = \"\"\"Michael is at that really famous museum in France looking at its most famous painting. \n",
    "    However, the name of the artist who made this painting just makes Michael think of his favourite cartoon character from his childhood. \n",
    "    What was the country of origin of the thing that the cartoon character usually holds in his hand?\"\"\"\n",
    "response = llm.invoke(zero_shot_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50dbb1",
   "metadata": {},
   "source": [
    "# 5. Chain-of-Thought Prompting\n",
    "\n",
    "This approach involves prompting the model to articulate its reasoning process step by step. \n",
    "\n",
    "It helps the model to tackle complex tasks that require multiple inferential steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99edab54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Ah, I see. Let's break it down step by step. \\n\\n1. Michael is at a famous museum in France looking at its most famous painting. This implies that the painting was created by a French artist.\\n\\n2. The name of the artist makes Michael think of his favorite cartoon character from his childhood. This suggests that the artist's name is somehow related to the cartoon character.\\n\\n3. The cartoon character usually holds something in his hand. Since we are looking for the country of origin of this object, it is likely that the object is associated with the country of origin of the cartoon character.\\n\\nPutting it all together, if the artist's name is related to the cartoon character, and the cartoon character's usual object is associated with a particular country, we can infer that the artist is French, the cartoon character is French or associated with France, and the object is also associated with France. \\n\\nTherefore, the country of origin of the object that the cartoon character usually holds in his hand is France.\"\n"
     ]
    }
   ],
   "source": [
    "chain_thought_prompt = \"\"\"Hello Sherlock Holmes! Can you help me solve this difficult puzzle? \n",
    "    Let's use chain-of-thought reasoning to figure this out.\n",
    "    Michael is at that really famous museum in France looking at its most famous painting. \n",
    "    However, the name of the artist who made this painting just makes Michael think of his favourite cartoon character from his childhood. \n",
    "    What was the country of origin of the thing that the cartoon character usually holds in his hand?\n",
    "    Keep in mind that humans often free associate ideas, so there's probably a link from each thing to the next.\"\"\"\n",
    "response = llm.invoke(chain_thought_prompt)\n",
    "\n",
    "# makes answer into a string for better output\n",
    "response = str(response)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
