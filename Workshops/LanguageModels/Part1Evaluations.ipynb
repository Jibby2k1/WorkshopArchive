{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/sosa.s/.local/lib/python3.11/site-packages (4.38.1)\n",
      "Requirement already satisfied: evaluate in /home/sosa.s/.local/lib/python3.11/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets in /home/sosa.s/.local/lib/python3.11/site-packages (2.17.1)\n",
      "Requirement already satisfied: nltk in /home/sosa.s/.local/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: rouge_score in /home/sosa.s/.local/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: filelock in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/sosa.s/.local/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sosa.s/.local/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/sosa.s/.local/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/sosa.s/.local/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/sosa.s/.local/lib/python3.11/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: dill in /home/sosa.s/.local/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from evaluate) (2.2.0)\n",
      "Requirement already satisfied: xxhash in /home/sosa.s/.local/lib/python3.11/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/sosa.s/.local/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/sosa.s/.local/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
      "Requirement already satisfied: responses<0.19 in /home/sosa.s/.local/lib/python3.11/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/sosa.s/.local/lib/python3.11/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/sosa.s/.local/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: aiohttp in /home/sosa.s/.local/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: click in /home/sosa.s/.local/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: absl-py in /home/sosa.s/.local/lib/python3.11/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sosa.s/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sosa.s/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sosa.s/.local/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/sosa.s/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /apps/pytorch/2.0.1b/lib/python3.11/site-packages (from pandas->evaluate) (2024.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers evaluate datasets nltk rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "## [Motiviation](https://youtu.be/Gg-w_n9NJIE?si=CncRwPnRWdphKVVc&t=2010)\n",
    "#### ref\n",
    "- [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/)\n",
    "- [Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena](https://arxiv.org/pdf/2306.05685.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Evaluations\n",
    "- [Chatbot Arena](https://chat.lmsys.org/?arena%3Fref=futuretools.io)\n",
    "- [GodMode](https://github.com/smol-ai/GodMode)\n",
    "## Symbolic evaluations\n",
    "### N-gram\n",
    "Contiguous sequence of n-items\n",
    "\n",
    "```\n",
    "reference = \"the quick brown fox\"\n",
    "prediction = \"the quick brown dog\"\n",
    "\n",
    "1_gram_matches = [\"the\", \"quick\", \"brown\"]\n",
    "1_gram_reference = [\"the\", \"quick\", \"brown\", \"fox\"]\n",
    "1_gram_result = 3/4\n",
    "\n",
    "2_gram_matches = [\"the quick\", \"quick brown\"]\n",
    "2_gram_reference = [\"the quick\", \"quick brown\", \"brown fox\"]\n",
    "2_gram_result = 2/3\n",
    "```\n",
    "\n",
    "### Sentence comparison\n",
    "#### BLEU (Bilingual evaluation understudy)\n",
    "\n",
    "<img src=\"BLEU.JPG\">\n",
    "\n",
    "- reawards brevity\n",
    "- geometric mean of the n-grams from 1-4\n",
    "\n",
    "https://cloud.google.com/translate/automl/docs/evaluate#bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa.s/.local/lib/python3.11/site-packages/datasets/load.py:753: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.1/metrics/bleu/bleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.668740304976422, 'precisions': [0.8, 0.75, 0.6666666666666666, 0.5], 'brevity_penalty': 1.0, 'length_ratio': 1.25, 'translation_length': 5, 'reference_length': 4}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "bleu = load_metric(\"bleu\") # \n",
    "predictions = [[\"the\", \"quick\", \"brown\", \"fox\", \"fox\"]] # posit this is a prediction of a translation from from \"El gato esta en la alfombra\"\n",
    "references = [[[\"the\", \"quick\", \"brown\", \"fox\"], [\"the\", \"quick\", \"brown\", \"cat\"]]]\n",
    "score = bleu.compute(predictions=predictions, references=references)\n",
    "print(score) # calculate the geometric mean of the precision of the n-grams with n=1,2,3,4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROUGE (Recall-oriented understudy for gisting evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa.s/.local/lib/python3.11/site-packages/datasets/load.py:753: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.1/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': AggregateScore(low=Score(precision=0.8, recall=1.0, fmeasure=0.888888888888889), mid=Score(precision=0.8, recall=1.0, fmeasure=0.888888888888889), high=Score(precision=0.8, recall=1.0, fmeasure=0.888888888888889)), 'rouge2': AggregateScore(low=Score(precision=0.75, recall=1.0, fmeasure=0.8571428571428571), mid=Score(precision=0.75, recall=1.0, fmeasure=0.8571428571428571), high=Score(precision=0.75, recall=1.0, fmeasure=0.8571428571428571)), 'rougeL': AggregateScore(low=Score(precision=0.8, recall=1.0, fmeasure=0.888888888888889), mid=Score(precision=0.8, recall=1.0, fmeasure=0.888888888888889), high=Score(precision=0.8, recall=1.0, fmeasure=0.888888888888889)), 'rougeLsum': AggregateScore(low=Score(precision=0.8, recall=1.0, fmeasure=0.888888888888889), mid=Score(precision=0.8, recall=1.0, fmeasure=0.888888888888889), high=Score(precision=0.8, recall=1.0, fmeasure=0.888888888888889))}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "rouge = load_metric(\"rouge\") # \n",
    "predictions = [\"the quick brown fox fox\"]\n",
    "references = [\"the quick brown fox\"]\n",
    "score = rouge.compute(predictions=predictions, references=references)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic evaluations\n",
    "<img src=\"img/Llama2-performance.JPG\">\n",
    "\n",
    "### MMLU (Massive Multitask Language Understanding)\n",
    "- [HuggingFace dataset](https://huggingface.co/datasets/lukaemon/mmlu)\n",
    "- [Measuring Massive Multitask Language Understanding](https://arxiv.org/abs/2009.03300)\n",
    "\n",
    "<img src=\"img/MMLU--domains.JPG\">\n",
    "\n",
    "A dataset consisting of multiple choice questions across a range of categories\n",
    "\n",
    "<img src=\"img/HellaSwag-ex.JPG\">\n",
    " \n",
    "### ChatBot Arena\n",
    "[Gradio client](https://chat.lmsys.org/?arena%3Fref=futuretools.io)\n",
    "\n",
    "### HellaSwag\n",
    "[HellaSwag: Can a Machine Really Finish Your Sentence?](https://arxiv.org/abs/1905.07830)\n",
    "\n",
    "Through adverserial filtering where discriminators select for the best incorrect answers to trick the LLM into selecting the wrong answer.\n",
    "\n",
    "### MT-Bench x LLM as a judge\n",
    "Uses LLM as a judge to to evaluate the performance in a multi-turn conversation  \n",
    "\n",
    "[Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena](https://arxiv.org/pdf/2306.05685.pdf)\n",
    "\n",
    "<img src=\"img/LLM_judge-agreement.JPG\">\n",
    "\n",
    "Actual implementation: https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5249ac485544af29ad290131d5a5a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "from torch import bfloat16\n",
    "\n",
    "model_instruct = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "tokenizer_instruct = transformers.AutoTokenizer.from_pretrained(model_instruct)\n",
    "pipeline = transformers.pipeline(\n",
    "    model=model_instruct,\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs={\"torch_dtype\": bfloat16, \"device_map\": \"auto\"},\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa.s/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1: Title: Aloha from the Heart of Hawaii: Unforgettable Cultur... | Token length: 680\n",
      "Answer 2: Title: Aloha from the Heart of Hawaii: Unforgettable Cultur... | Token length: 467\n"
     ]
    }
   ],
   "source": [
    "question_1 = \"Compose an engaging travel blog post about a recent trip to Hawaii, highlighting cultural experiences and must-see attractions.\"\n",
    "ref_answer_1 = \"Title: Aloha, Hawaii! A Cultural and Natural Paradise Awaits\\n\\nSubheading: Uncovering the Rich Culture and Breathtaking Beauty of Hawaii\\n\\nAloha, fellow travelers! I recently embarked on an unforgettable journey to the heart of the Pacific Ocean, the stunning Hawaiian Islands. From the moment I stepped off the plane, I was enveloped by the welcoming spirit of Aloha, and I couldn't wait to explore the rich cultural experiences and must-see attractions that awaited me.\\n\\nMy first stop was the bustling city of Honolulu, located on the island of Oahu. As the state capital, Honolulu is the perfect starting point for any Hawaiian adventure. I immediately immersed myself in the local culture with a visit to the Bishop Museum, which houses the world's most extensive collection of Polynesian cultural artifacts. Here, I learned about the fascinating history of the Hawaiian people and marveled at the intricate craftsmanship of traditional Hawaiian quilts, feather capes, and ancient wooden carvings.\\n\\nAfter exploring the museum, I ventured to the iconic Iolani Palace, the only royal palace in the United States. The palace was the official residence of the Hawaiian monarchy from 1882 until its overthrow in 1893. The beautifully restored palace offered a unique glimpse into the lavish lifestyle of the Hawaiian royals, and I couldn't help but be captivated by the elegant architecture and lush, manicured gardens.\\n\\nThe next day, I took a short drive to the nearby Polynesian Cultural Center, where I was treated to an unforgettable luau experience. I watched in awe as skilled performers showcased traditional dances and music from various Polynesian cultures, including Hawaiian hula, Samoan fire knife dancing, and Maori poi spinning. The delicious feast that accompanied the performance featured mouthwatering kalua pig, lomi salmon, and haupia, a coconut milk-based dessert.\\n\\nAfter indulging in the cultural experiences of Oahu, it was time to explore the natural beauty of the Hawaiian Islands. I hopped on a short flight to the Big Island, where I was greeted by the awe-inspiring sight of Kilauea, one of the world's most active volcanoes. I took a guided hike through Hawaii Volcanoes National Park, where I was able to witness the raw power of nature as molten lava flowed into the sea, creating a dramatic plume of steam and ash.\\n\\nAs I continued my journey through the Big Island, I was struck by the island's diverse landscape. From the lush rainforests and cascading waterfalls of the Hamakua Coast to the black sand beaches of Punalu'u and the snow-capped peaks of Mauna Kea, there was no shortage of breathtaking scenery to discover.\\n\\nNo trip to Hawaii would be complete without visiting the enchanting island of Maui. I spent my days lounging on the pristine beaches of Ka'anapali and Wailea, snorkeling with sea turtles in the crystal-clear waters of Molokini, and driving the legendary Road to Hana, with its countless waterfalls and panoramic ocean views.\\n\\nAs my Hawaiian adventure came to a close, I couldn't help but be grateful for the incredible experiences I had encountered. From the rich cultural heritage of the Hawaiian people to the stunning natural beauty of the islands, Hawaii is truly a paradise waiting to be discovered. So, pack your bags and say \\\"Aloha\\\" to your next unforgettable journey - Hawaii is calling!\"\n",
    "question_2 = \"Rewrite your previous response. Start every sentence with the letter A.\"\n",
    "ref_answer_2 = \"Astonishing adventures awaited me in Hawaii, the heart of the Pacific Ocean. Aroused by the spirit of Aloha from the moment I stepped off the plane, I anticipated the rich cultural experiences and must-see attractions I would encounter. Arriving in Honolulu, located on the island of Oahu, I appreciated the bustling atmosphere and the perfect starting point for any Hawaiian journey. A visit to the Bishop Museum immersed me in the local culture, admiring the world's most extensive collection of Polynesian cultural artifacts. Ancient Hawaiian quilts, feather capes, and wooden carvings held an alluring beauty.\\n\\nAn iconic attraction, Iolani Palace, drew my attention next. As the only royal palace in the United States, it housed the Hawaiian monarchy from 1882 until 1893. Architectural elegance and lush, manicured gardens captivated me during my visit. Another day, a short drive took me to the Polynesian Cultural Center for an unforgettable luau experience. Awe-inspiring performances of traditional dances and music from various Polynesian cultures filled the evening, including Hawaiian hula, Samoan fire knife dancing, and Maori poi spinning. Appetizing feasts featured mouthwatering kalua pig, lomi salmon, and haupia, a coconut milk-based dessert.\\n\\nAdventuring to the Big Island, I marveled at Kilauea, one of the world's most active volcanoes. A guided hike through Hawaii Volcanoes National Park allowed me to witness the raw power of nature, as molten lava flowed into the sea. Amidst the diverse landscape of the Big Island, I found lush rainforests, cascading waterfalls, black sand beaches, and snow-capped peaks.\\n\\nArriving in Maui, I enjoyed pristine beaches, snorkeling with sea turtles, and driving the legendary Road to Hana. As my Hawaiian adventure neared its end, appreciation for the incredible experiences filled me. Aloha to Hawaii, a paradise of rich cultural heritage and stunning natural beauty, where unforgettable memories are made!\"\n",
    "\n",
    "prompt = f\"<s>[INST] {question_1} [/INST]\"\n",
    "\n",
    "generated_res_1 = pipeline(prompt, max_new_tokens=1000, do_sample=True, temperature=0.01, top_k=1)[0]['generated_text']\n",
    "answer_1 = generated_res_1.split(\"[/INST]\")[1]\n",
    "print(\"Answer 1:\" + answer_1[0:60] + \"... | Token length: \" + str(len(tokenizer_instruct.encode(answer_1, return_tensors=\"pt\")[0])))\n",
    "prompt = generated_res_1 + \"</s>\" + f\"[INST] {question_2}[/INST]\"\n",
    "generated_res_2 = pipeline(prompt, max_new_tokens=1000, do_sample=True, temperature=0.01, top_k=1)[0]['generated_text']\n",
    "answer_2 = generated_res_2.split(\"[/INST]\")[2]\n",
    "print(\"Answer 2:\" + answer_2[0:60] + \"... | Token length: \" + str(len(tokenizer_instruct.encode(answer_2, return_tensors=\"pt\")[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1:\n",
      " Title: Aloha from the Heart of Hawaii: Unforgettable Cultural Experiences and Breathtaking Attractions\n",
      "\n",
      "As I step off the plane, the warm, tropical air of Hawaii greets me with a gentle caress, carrying the sweet scent of blooming hibiscus and the soothing sound of traditional Hawaiian music. The vibrant colors of the island's landscape unfold before me, a stunning tapestry of lush greenery, crys...\n",
      "\n",
      "Answer 2:\n",
      " Title: Aloha from the Heart of Hawaii: Unforgettable Cultural Experiences and Breathtaking Attractions\n",
      "\n",
      "Aloha and welcome to my travel blog, where I share my recent journey to the heart of Hawaii. As I stepped off the plane, I was greeted by the warm, tropical air, carrying the sweet scent of blooming hibiscus and the soothing sound of traditional Hawaiian music.\n",
      "\n",
      "An array of vibrant colors unfol...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Answer 1:\\n{answer_1[0:400]}...\\n\\nAnswer 2:\\n{answer_2[0:400]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa.s/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_score:  Rating: [[10]]\n",
      "\n",
      "Assistant A's response is an excellent rewrite of the reference answer, starting every sentence with the letter \"A.\" The response maintains the original's engaging tone and highlights the cultural experiences and must-see attractions in Hawaii. There are no mistakes or incorrect information in the response. Overall, it is a well-written and helpful answer.\n"
     ]
    }
   ],
   "source": [
    "generated_score = pipeline(f\"\"\"<s>[INST] Please act as an impartial judge and evaluate the quality of the response provided by an \n",
    "AI assistant to the user question. Your evaluation should consider correctness and \n",
    "helpfulness. You will be given a reference answer and the assistant's answer. You \n",
    "evaluation should focus on the assistant's answer to the second question. Begin your \n",
    "evaluation by comparing the assistant's answer with the reference answer. Identify and \n",
    "correct any mistakes. Be as objective as possible. After providing your explanation, you \n",
    "must rate the response on a scale of 1 to 10 by strictly following this format: \n",
    "\"[[rating]]\", for example: \"Rating: [[5]]\".\n",
    "<|The Start of Reference Answer|>\n",
    "### User:\n",
    "{question_1}\n",
    "### Reference answer:\n",
    "{ref_answer_1}\n",
    "### User:\n",
    "{question_2}\n",
    "### Reference answer:\n",
    "{ref_answer_2}\n",
    "<|The End of Reference Answer|>\n",
    "<|The Start of Assistant A's Conversation with User|>\n",
    "### User:\n",
    "{question_1} \n",
    "### Assistant A:\n",
    "{answer_1}\n",
    "### User:\n",
    "{question_2}\n",
    "### Assistant A:\n",
    "{answer_2}\n",
    "<|The End of Assistant A's Conversation with User|> [/INST]\"\"\", max_new_tokens=1000, do_sample=True, temperature=0.01, top_k=1)[0]['generated_text']\n",
    "response = generated_score.split(\"[/INST]\")[1]\n",
    "print(\"generated_score: \" + response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.tenor.com/-iop9obK0IwAAAAe/i-want-to-play-a-game-play-time.png\">\n",
    "\n",
    "- If you correctly answer 4 MMLU questions then you are smarter than Llama-2!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
